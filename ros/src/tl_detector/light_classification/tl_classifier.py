from styx_msgs.msg import TrafficLight

import tensorflow as tf
import numpy as np
import cv2
import os
import rospy

from timeit import default_timer as timer


CLASS_TRAFFIC_LIGHT = 10

MODEL_DIR = 'light_classification/models/'
IMG_DIR = 'light_classification/img/'
DEBUG_DIR = 'light_classification/debug/'

class TLClassifier(object):
    def __init__(self, profiling=True):
        if not os.path.exists(DEBUG_DIR):
            os.makedirs(DEBUG_DIR)
        #rospy.logwarn("%s", os.getcwd())
        self.detector = MODEL_DIR + 'faster_rcnn_inception_v2.pb'
        rospy.logwarn("----------------------------------------------------------------------------------")
        rospy.logwarn("With SIMULATOR: use lowest screen resolution 640x480 with Graphics Quality FASTEST")
        rospy.logwarn("With SIMULATOR: so that the GPU is mainly dedicated to running object detection")
        rospy.logwarn("----------------------------------------------------------------------------------")
        rospy.logwarn("PLEASE WAIT for TENSORFLOW init ... There will be a READY TO GO message")
        rospy.logwarn("----------------------------------------------------------------------------------")
        self.sess, _ = self.load_graph(self.detector)
        detection_graph = self.sess.graph
        
        # The input placeholder for the image.
        # `get_tensor_by_name` returns the Tensor with the associated name in the Graph.
        self.image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
        # Each box represents a part of the image where a particular object was detected.
        self.detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
        # Each score represent how level of confidence for each of the objects.
        # Score is shown on the result image, together with the class label.
        self.detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
        # The classification of the object (integer id).
        self.detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')

        self.profiling = profiling

        # the very first decoding is slow: al inits are done
        # => do that in advance before real decoding
        for i in range(2):
            #test_image = cv2.imread('light_classification/img/left0144.jpg')
            test_image = cv2.imread(IMG_DIR + 'left0144.jpg')
            pred_image, is_red = self.detect_tl(test_image)
            if is_red:
                print("RED")
            else:
                print("NOT RED")
            #cv2.imwrite("light_classification/img/pred_image.png", pred_image)
            cv2.imwrite(IMG_DIR + 'pred_image.png', pred_image)

        rospy.logwarn("----------------------------------------------------------------------------------")
        rospy.logwarn("TENSORFLOW init done ... READY TO GO")
        rospy.logwarn("----------------------------------------------------------------------------------")
        self.num_image = 1

    def load_graph(self, graph_file, use_xla=False):
        config = tf.ConfigProto()
        if use_xla:
            jit_level = tf.OptimizerOptions.ON_1
            config.graph_options.optimizer_options.global_jit_level = jit_level
    
        with tf.Session(graph=tf.Graph(), config=config) as sess:
            gd = tf.GraphDef()
            with tf.gfile.Open(graph_file, 'rb') as f:
                data = f.read()
                gd.ParseFromString(data)
            tf.import_graph_def(gd, name='')
            ops = sess.graph.get_operations()
            n_ops = len(ops)
            print("number of operations = %d" % n_ops)
            return sess, ops

    def filter_boxes(self, min_score, boxes, scores, classes):
        """Return boxes with a confidence >= `min_score`"""
        n = len(classes)
        idxs = []
        for i in range(n):
            if scores[i] >= min_score:
                idxs.append(i)
        filtered_boxes = boxes[idxs, ...]
        filtered_scores = scores[idxs, ...]
        filtered_classes = classes[idxs, ...]
        return filtered_boxes, filtered_scores, filtered_classes
    
    def to_image_coords(self, boxes, height, width):
        """
        The original box coordinate output is normalized, i.e [0, 1].
        This converts it back to the original coordinate based on the image
        size.
        """
        box_coords = np.zeros_like(boxes)
        box_coords[:, 0] = boxes[:, 0] * height
        box_coords[:, 1] = boxes[:, 1] * width
        box_coords[:, 2] = boxes[:, 2] * height
        box_coords[:, 3] = boxes[:, 3] * width
        return box_coords
    
    def select_lighton_real(self, img): # HLS for real
        """Applies color selection for high L and S """
        hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)
        lower = np.array([ 50,   150, 150], dtype="uint8")
        upper = np.array([ 100, 255, 255], dtype="uint8")
        tl_mask = cv2.inRange(hls_img, lower, upper)
        return cv2.bitwise_and(img, img, mask = tl_mask)
    
    def select_red_simu(self, img): # BGR for simu
        lower = np.array([ 0,   0, 200], dtype="uint8")
        upper = np.array([ 50, 50, 255], dtype="uint8")
        red_mask = cv2.inRange(img, lower, upper)
        return cv2.bitwise_and(img, img, mask = red_mask)
    
    def classify_red_tl(self, image_np, boxes, classes, scores, thickness=4):
        """Draw bounding boxes on the image"""
        for i in range(len(boxes)):
            bot, left, top, right = boxes[i, ...]
            class_id = int(classes[i])
            score = scores[i]
            if class_id == CLASS_TRAFFIC_LIGHT:
                h = top - bot
                w = right - left
                if h <= 1.5 * w:
                    continue # Truncated Traffic Ligth box
                cv2.rectangle(image_np,(left, top), (right, bot), (255, 0, 0), thickness) # BGR format for color
                tl_img = image_np[int(bot):int(top), int(left):int(right)]
    
                tl_img_simu = self.select_red_simu(tl_img) # SELECT RED
                tl_img_real = self.select_lighton_real(tl_img) # SELECT TL
                tl_img = (tl_img_simu + tl_img_real) / 2
    
                gray_tl_img = cv2.cvtColor(tl_img, cv2.COLOR_RGB2GRAY)
                nrows, ncols = gray_tl_img.shape[0], gray_tl_img.shape[1]
    
                # compute center of mass of RED points
                mean_row = 0
                mean_col = 0
                npoints = 0
                for row in range(nrows):
                    for col in range(ncols):
                        if (gray_tl_img[row, col] > 0): 
                            mean_row += row
                            mean_col += col
                            npoints += 1
                if npoints > 0:
                  mean_row = float(mean_row / npoints) / nrows
                  mean_col = float(mean_col / npoints) / ncols
                  #print(mean_row, mean_col, npoints)
    
                  # if normalized center of mass of RED points 
                  # is in the upper part of detected Traffic Light Box
                  # THEN it is a RED traffic light
                  if npoints > 10 and mean_row < 0.33:
                      text = "RED LIGHT score=%.3f" % score
                      cv2.putText(image_np, text, (int(left), int(bot)), cv2.FONT_HERSHEY_SIMPLEX, 
                                                   1, (0,0,255), 2, lineType=cv2.LINE_AA)
                      return image_np, True
        return image_np, False

    def detect_tl(self, image):
        start = timer()
        trt_image = np.copy(image)
        image_np = np.expand_dims(np.asarray(trt_image, dtype=np.uint8), 0)
    
        start_inference = timer()
        # Actual detection.
        (boxes, scores, classes) = self.sess.run([self.detection_boxes, self.detection_scores, self.detection_classes], 
                                            feed_dict={self.image_tensor: image_np})
        end_inference = timer()
    
        # Remove unnecessary dimensions
        boxes = np.squeeze(boxes)
        scores = np.squeeze(scores)
        classes = np.squeeze(classes)
    
        confidence_cutoff = 0.8
        # Filter boxes with a confidence score less than `confidence_cutoff`
        boxes, scores, classes = self.filter_boxes(confidence_cutoff, boxes, scores, classes)
    
        # The current box coordinates are normalized to a range between 0 and 1.
        # This converts the coordinates actual location on the image.
        image_np = np.squeeze(image_np)
        width = image_np.shape[1]
        height = image_np.shape[0]
        box_coords = self.to_image_coords(boxes, height, width)
    
        # Each class with be represented by a differently colored box
        image_np, is_red = self.classify_red_tl(image_np, box_coords, classes, scores)
        end = timer()
    
        if self.profiling:
            time_inference = end_inference - start_inference
            time_img_processing = (end - start) - time_inference
            print("time: inference {:.6f} post-processing {:.6f}".format(time_inference, time_img_processing))
        return image_np, is_red

    def get_classification(self, image):
        """Determines the color of the traffic light in the image

        Args:
            image (cv::Mat): image containing the traffic light

        Returns:
            int: ID of traffic light color (specified in styx_msgs/TrafficLight)

        """
        # light color prediction
        pred_image, is_red = self.detect_tl(image)
        fimage = DEBUG_DIR + 'image' + str(self.num_image) + '.png'
        cv2.imwrite(fimage, pred_image)
        self.num_image += 1

        if is_red:
            return TrafficLight.RED
        else:
            return TrafficLight.UNKNOWN
